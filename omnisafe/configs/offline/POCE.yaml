# Copyright 2023 OmniSafe Team. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================

defaults:
  # seed for random number generator
  seed: 5
  # training configurations
  train_cfgs:
    # device to use for training, options: cpu, cuda, cuda:0, cuda:0,1, etc.
    device: cuda:7
    # number of threads for torch
    torch_threads: 16
    # total number of steps to train
    total_steps: 1000000
    # dataset name
    dataset: ./dataset/SafetyPointGoal1-v0_data_82.npz
    # evaluate_epoisodes
    evaluate_epoisodes: 1
    # parallel, offline only supports 1
    parallel: 1
    # vector_env_nums, offline only supports 1
    vector_env_nums: 1
    # The max step of one episode
    ep_step: 500
    # frequence for the evaluate 
    eval_freq: 50
  # algorithm configurations
  algo_cfgs:
    # Tolerance of constraint violation
    cost_limit: 5
    # the cost increase limit
    cost_increase_limit: 0.8
    # gamma used in RL
    gamma: 0.99
    # beat in Crr, f := exp(A(s, a) / beta)
    beta: 1
    # batch size
    batch_size: 256
    # step per epoch, algo will log and eval every epoch
    steps_per_epoch: 1000
    # phi used in BCQ
    phi: 0.05
    # sample action numbers when update critic
    sampled_action_num: 10
    # The number of the sample action
    action_num: 10
    # minimum weighting when compute Q, Q = w * min(q1, q2) + (1 - w) * max(q1, q2)
    polyak: 0.005
    # when starting lagrange update
    lagrange_start_step: 150000
    # the tolerance of cost limit
    tolerance: 0
    # the max tolerance of cost limit
    max_tolerance: 10
    # the min tolrance of cost limit
    min_tolerance: 0
    # The value of alpha
    alpha: 0.2
    # Whether to use auto alpha
    auto_alpha: False
    # max gradient norm
    max_grad_norm: 40
    # use critic norm
    use_critic_norm: False
    # critic norm coefficient
    critic_norm_coeff: 0.001
    # The ratio of the MCQ
    lam: 0.995
    # loss_r_value 
    r_value: 12
  # logger configurations
  logger_cfgs:
    # use wandb for logging
    use_wandb: True
    # wandb project name
    wandb_project: poce
    # use tensorboard for logging
    use_tensorboard: True
    # save model frequency
    save_model_freq: 100
    # save logger path
    log_dir: "./runs"
  # model configurations
  model_cfgs:
    # The mode to initiate the weight of network, choosing from "kaiming_uniform", "xavier_normal", "glorot" and "orthogonal".
    weight_initialization_mode: "kaiming_uniform"
    # actor's cfgs
    actor:
      # Size of hidden layers
      hidden_sizes: [256, 256, 256]
      # Type of activation function, choosing from "tanh", "relu", "sigmoid", "identity", "softplus"
      activation: relu
      # Learning rate of model
      lr: 0.00005
    # critic's cfgs
    critic:
      # Size of hidden layers
      hidden_sizes: [256, 256, 256]
      # Type of activation function, choosing from "tanh", "relu", "sigmoid", "identity", "softplus"
      activation: relu
      # Learning rate of model
      lr: 0.0001
    vae:
      # The number of neurons in the hidden layer
      vae_features: 750
      # The layer of the VAE
      vae_layers: 2
      # The learning rate of the VAE network
      vae_lr: 0.001
      # The training step of the VAE network
      vae_step: 200000
  # lagrangian configurations
  lagrange_cfgs:
    # Tolerance of constraint violation
    cost_limit: 5.0
    # Initial value of lagrangian multiplier
    lagrangian_multiplier_init: 1.0
    # Learning rate of lagrangian multiplier
    lambda_lr: 0.001
    # Type of lagrangian optimizer
    lambda_optimizer: "Adam"


SafetyPointGoal1-v0:
  # algorithm configurations
  algo_cfgs:
    # loss_r_value 
    r_value: 12
    # normalize cost
    cost_normalize: False
  # model configurations
  model_cfgs:
    # Configuration of Actor network
    actor:
      # The learning rate of Actor network
      lr: 0.00005
    # Configuration of Critic network
    critic:
      # The learning rate of Critic network
      lr: 0.0001
  # lagrangian configurations
  lagrange_cfgs:
    # Tolerance of constraint violation
    cost_limit: 5
    # Type of lagrangian optimizer
    lambda_optimizer: "Adam"


SafetyCarGoal1-v0:
  # algorithm configurations
  algo_cfgs:
    # loss_r_value 
    r_value: 12.5
    # normalize cost
    cost_normalize: False
  # model configurations
  model_cfgs:
    # Configuration of Actor network
    actor:
      # The learning rate of Actor network
      lr: 0.00005
    # Configuration of Critic network
    critic:
      # The learning rate of Critic network
      lr: 0.0001
  # lagrangian configurations
  lagrange_cfgs:
    # Tolerance of constraint violation
    cost_limit: 5
    # Type of lagrangian optimizer
    lambda_optimizer: "Adam"



SafetyAntVelocity-v1:
  # algorithm configurations
  algo_cfgs:
    # loss_r_value 
    r_value: 1000
    # normalize cost
    cost_normalize: False
  # model configurations
  model_cfgs:
    # Configuration of Actor network
    actor:
      # The learning rate of Actor network
      lr: 0.00005
    # Configuration of Critic network
    critic:
      # The learning rate of Critic network
      lr: 0.0001
  # lagrangian configurations
  lagrange_cfgs:
    # Tolerance of constraint violation
    cost_limit: 5
    # Type of lagrangian optimizer
    lambda_optimizer: "Adam"


  

